import pandas as pd
import sqlite3
from typing import List
import logging

def upsert_dataframe(df: pd.DataFrame, 
                     table_name: str,
                     unique_columns: List[str],
                     db_path: str) -> dict:
    """
    Upsert (insert or replace) DataFrame rows into a SQLite database table.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        DataFrame containing the rows to upsert
    table_name : str
        Name of the target database table
    unique_columns : List[str]
        List of column names that uniquely identify a row
    db_path : str
        Path to the SQLite database file
        
    Returns:
    --------
    dict
        Summary of operations performed
    """
    try:
        # Connect to database
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Get the list of columns in the table
        cursor.execute(f"PRAGMA table_info({table_name})")
        table_columns = [col[1] for col in cursor.fetchall()]
        
        # Ensure DataFrame columns match table columns
        df_columns = set(df.columns)
        table_columns_set = set(table_columns)
        if not df_columns.issubset(table_columns_set):
            invalid_columns = df_columns - table_columns_set
            raise ValueError(f"DataFrame contains columns not in table: {invalid_columns}")
        
        # Create the unique index if it doesn't exist
        index_name = f"idx_{table_name}_{'_'.join(unique_columns)}"
        index_columns = ', '.join(unique_columns)
        cursor.execute(f"""
            CREATE UNIQUE INDEX IF NOT EXISTS {index_name} 
            ON {table_name} ({index_columns})
        """)
        
        # Prepare the INSERT OR REPLACE statement
        columns = ', '.join(df.columns)
        placeholders = ', '.join(['?' for _ in df.columns])
        query = f"""
            INSERT OR REPLACE INTO {table_name} ({columns})
            VALUES ({placeholders})
        """
        
        # Convert DataFrame to list of tuples for execution
        records = df.to_records(index=False)
        data = [tuple(record) for record in records]
        
        # Execute the upsert
        cursor.executemany(query, data)
        rows_affected = cursor.rowcount
        
        # Commit and close
        conn.commit()
        conn.close()
        
        return {
            'status': 'success',
            'rows_affected': rows_affected,
            'message': f'Successfully upserted {rows_affected} rows'
        }
        
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        return {
            'status': 'error',
            'rows_affected': 0,
            'message': f'Error during upsert: {str(e)}'
        }

def get_existing_records(db_path: str, 
                        table_name: str, 
                        unique_columns: List[str], 
                        df: pd.DataFrame) -> pd.DataFrame:
    """
    Get existing records from SQLite database that match the DataFrame's unique columns.
    
    Parameters:
    -----------
    db_path : str
        Path to the SQLite database file
    table_name : str
        Name of the target database table
    unique_columns : List[str]
        List of column names that uniquely identify a row
    df : pandas.DataFrame
        DataFrame to check against database
        
    Returns:
    --------
    pandas.DataFrame
        Matching records from database
    """
    try:
        conn = sqlite3.connect(db_path)
        
        # Create the WHERE clause for unique columns
        where_conditions = []
        params = []
        for col in unique_columns:
            unique_values = df[col].unique().tolist()
            placeholders = ','.join(['?' for _ in unique_values])
            where_conditions.append(f"{col} IN ({placeholders})")
            params.extend(unique_values)
        
        where_clause = ' AND '.join(where_conditions)
        query = f"SELECT * FROM {table_name} WHERE {where_clause}"
        
        # Execute query and return results as DataFrame
        existing_records = pd.read_sql_query(query, conn, params=params)
        conn.close()
        
        return existing_records
        
    except Exception as e:
        if 'conn' in locals():
            conn.close()
        raise e
